
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.1, mkdocs-material-8.5.7">
    
    
      
        <title>Clothes Retrieval - Hetul Patel</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.20d9efc8.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.cbb835fc.min.css">
        
          
          
          <meta name="theme-color" content="#ffffff">
        
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="white" data-md-color-accent="">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#clothes-retrieval" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Hetul Patel" class="md-header__button md-logo" aria-label="Hetul Patel" data-md-component="logo">
      
  <img src="../../assets/icons8-code-64.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Hetul Patel
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Clothes Retrieval
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Hetul Patel" class="md-nav__button md-logo" aria-label="Hetul Patel" data-md-component="logo">
      
  <img src="../../assets/icons8-code-64.png" alt="logo">

    </a>
    Hetul Patel
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Hello! ðŸ‘‹
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../experience/" class="md-nav__link">
        Experience
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Projects
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Projects" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Projects
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Clothes Retrieval
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Clothes Retrieval
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#dataset-details" class="md-nav__link">
    Dataset Details
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#code" class="md-nav__link">
    Code
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#building-the-intuition" class="md-nav__link">
    Building the intuition
  </a>
  
    <nav class="md-nav" aria-label="Building the intuition">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-usecase-understanding" class="md-nav__link">
    1. Usecase understanding
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-dataset-understanding" class="md-nav__link">
    2. Dataset understanding
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-real-world-challenges" class="md-nav__link">
    3. Real world challenges
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#solving-the-problem" class="md-nav__link">
    Solving the problem
  </a>
  
    <nav class="md-nav" aria-label="Solving the problem">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#step-1-learning-directly-from-raw-images-without-labeling" class="md-nav__link">
    Step 1 : Learning directly from raw images without labeling
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-reducing-the-domain-gap-using-pinch-of-supervision" class="md-nav__link">
    Step 2 : Reducing the domain gap using pinch of supervision
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#experiments" class="md-nav__link">
    Experiments
  </a>
  
    <nav class="md-nav" aria-label="Experiments">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model-details" class="md-nav__link">
    Model details
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#results" class="md-nav__link">
    Results
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#final-comments" class="md-nav__link">
    Final Comments
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#demo-on-validation-dataset" class="md-nav__link">
    Demo on validation dataset
  </a>
  
    <nav class="md-nav" aria-label="Demo on validation dataset">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model-unsupervised-learning-attribute-loss-exp-1" class="md-nav__link">
    Model :  Unsupervised Learning + Attribute Loss (Exp 1)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-attribute-loss-instance-loss-fc7-weights-init-exp-2" class="md-nav__link">
    Model :  Attribute Loss + Instance Loss + fc7 weights init (Exp-2)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../deep_face_recognition/" class="md-nav__link">
        Deep Face Recognition
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../alpr/" class="md-nav__link">
        Automatic License Plate Recognition
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../auto_adaptive/" class="md-nav__link">
        Auto Adaptive Image Classifier
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../mind_controlled_home_automation/" class="md-nav__link">
        Mind Controlled Home Automation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../hyperspectral_image_classification/" class="md-nav__link">
        Hyper Spectral Image Classification
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lecture_notes_saving_app/" class="md-nav__link">
        Fellow (Lecture notes app)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../3d_password/" class="md-nav__link">
        3D Password
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../spry/" class="md-nav__link">
        Hospital Management System
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../small_face_detection/" class="md-nav__link">
        Small face detection
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../on_device_classification/" class="md-nav__link">
        On Device Object Classification
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../mobile_app_for_visually_impaired/" class="md-nav__link">
        Mobile app for visually impaired
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../talks/" class="md-nav__link">
        Talks/Seminars/Workshops
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../publications/" class="md-nav__link">
        Publications
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../education/" class="md-nav__link">
        Education
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../contact/" class="md-nav__link">
        Contact
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#dataset-details" class="md-nav__link">
    Dataset Details
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#code" class="md-nav__link">
    Code
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#building-the-intuition" class="md-nav__link">
    Building the intuition
  </a>
  
    <nav class="md-nav" aria-label="Building the intuition">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-usecase-understanding" class="md-nav__link">
    1. Usecase understanding
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-dataset-understanding" class="md-nav__link">
    2. Dataset understanding
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-real-world-challenges" class="md-nav__link">
    3. Real world challenges
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#solving-the-problem" class="md-nav__link">
    Solving the problem
  </a>
  
    <nav class="md-nav" aria-label="Solving the problem">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#step-1-learning-directly-from-raw-images-without-labeling" class="md-nav__link">
    Step 1 : Learning directly from raw images without labeling
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-reducing-the-domain-gap-using-pinch-of-supervision" class="md-nav__link">
    Step 2 : Reducing the domain gap using pinch of supervision
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#experiments" class="md-nav__link">
    Experiments
  </a>
  
    <nav class="md-nav" aria-label="Experiments">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model-details" class="md-nav__link">
    Model details
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#results" class="md-nav__link">
    Results
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#final-comments" class="md-nav__link">
    Final Comments
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#demo-on-validation-dataset" class="md-nav__link">
    Demo on validation dataset
  </a>
  
    <nav class="md-nav" aria-label="Demo on validation dataset">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model-unsupervised-learning-attribute-loss-exp-1" class="md-nav__link">
    Model :  Unsupervised Learning + Attribute Loss (Exp 1)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-attribute-loss-instance-loss-fc7-weights-init-exp-2" class="md-nav__link">
    Model :  Attribute Loss + Instance Loss + fc7 weights init (Exp-2)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="clothes-retrieval">Clothes Retrieval<a class="headerlink" href="#clothes-retrieval" title="Permanent link">&para;</a></h1>
<p>Searching for exact cloth image accurately from massive collections of clothes' images based on a query image.</p>
<p>For example, here the left most image is the query image and other images are matched images retrieved from a huge collection of clothes using a computer vision algorithm.</p>
<p><img alt="png" src="../../assets/projects/clothes_retrieval/demo.jpg" /></p>
<h2 id="dataset-details"><strong>Dataset Details</strong><a class="headerlink" href="#dataset-details" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>Dataset used</strong> : <a href="https://github.com/switchablenorms/DeepFashion2">Deep Fashion 2</a></li>
<li><strong>Problem statement</strong> : Consumer-to-shop <strong>Clothes Retrieval</strong></li>
<li><strong>Problem description</strong>: Matching consumer-taken photos with their shop counterparts</li>
</ul>
<h2 id="code"><strong>Code</strong><a class="headerlink" href="#code" title="Permanent link">&para;</a></h2>
<p><a href="https://colab.research.google.com/drive/1DyEZUDpnAjC2lyMUpSZgpWI4vAiAhwHg?usp=sharing" target="_blank">Google Colab</a></p>
<h2 id="building-the-intuition"><strong>Building the intuition</strong><a class="headerlink" href="#building-the-intuition" title="Permanent link">&para;</a></h2>
<p><i>Sorted in the order of how I reached the solution</i></p>
<h3 id="1-usecase-understanding">1. Usecase understanding<a class="headerlink" href="#1-usecase-understanding" title="Permanent link">&para;</a></h3>
<ul>
<li>Consumer can upload a photo of clothing item </li>
<li>System should <strong>retrieve similar looking items</strong> from shopping catalog.</li>
</ul>
<h3 id="2-dataset-understanding">2. Dataset understanding<a class="headerlink" href="#2-dataset-understanding" title="Permanent link">&para;</a></h3>
<p>In the given task, we have two different <strong>sources of data</strong>. </p>
<ul>
<li><strong>Consumer captured images :</strong> </li>
</ul>
<p>These are <strong>low quality</strong> images captured using phone's camera (front or back). Images have <strong>variation</strong> in lighting, orientation, occlusion, filters etc.</p>
<ul>
<li><strong>Shop captured images :</strong></li>
</ul>
<p>Shop images include <strong>good quality</strong> photo shoot quality images. It also includes images from online shopping carts where background is removed etc.</p>
<h3 id="3-real-world-challenges">3. Real world challenges<a class="headerlink" href="#3-real-world-challenges" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Labeling</strong> the dataset is major challenge</li>
<li>Shopping image collection including online and offline stores can be <strong>huge</strong></li>
<li>Thousands of <strong>unique clothing items</strong></li>
<li>Manually <strong>pairing</strong> each user captured image to a similar shop image costs lots of <strong>human effort</strong></li>
<li>When the product is new, we might not have huge collection of user captured images. In that case the system cannot work better for <strong>new styles</strong></li>
</ul>
<h2 id="solving-the-problem"><strong>Solving the problem</strong><a class="headerlink" href="#solving-the-problem" title="Permanent link">&para;</a></h2>
<p>Considering the <strong>scarcity</strong> of labeled consumer to shop pairs, I decided build <strong>two stage pipeline</strong>. First learning task agnostic <strong>attributes</strong> from raw data then use them to reduce consumer to shop <strong>domain gap</strong> using fewer labeled images.</p>
<h3 id="step-1-learning-directly-from-raw-images-without-labeling"><strong>Step 1</strong> : Learning directly from raw images without labeling<a class="headerlink" href="#step-1-learning-directly-from-raw-images-without-labeling" title="Permanent link">&para;</a></h3>
<p><strong>Observations</strong></p>
<ul>
<li>Humans are good at <strong>pattern matching</strong>. </li>
<li>We recognize many things from their <strong>attributes</strong>. For e.g we recognize a vehicle with wheels, seats, glasses, horn etc.</li>
<li>We also use this attributes to distinguish between two different vehicles</li>
<li>We learn about these attributes by <strong>comparing between many instances</strong> unconsciously</li>
</ul>
<p><strong>Inspirations</strong></p>
<ul>
<li>Deep learning model can also learn similar attributes by just <strong>observing</strong> across different images</li>
<li>In many image retrieval problems we consider output of pre-fc layer as <strong>embedding</strong></li>
<li>We use <strong>metric learning</strong> approaches such as triplet loss to lean <strong>discriminative embedding</strong></li>
<li>We can consider <strong>each dimension</strong> in embedding vector as one <strong>attribute</strong></li>
<li>This attributes make the embedding vector discriminative</li>
</ul>
<p><strong>Difference from metric learning</strong></p>
<ul>
<li>Metric learning approaches try to increase distance between embeddings <strong>as a whole</strong>. For that we need <strong>positive and negative pairs</strong>.</li>
</ul>
<p><img alt="png" src="../../assets/projects/clothes_retrieval/output_18_0.png" /></p>
<ul>
<li>Instead we can <strong>increase distance</strong> between attributes of embedding <strong>without labels</strong>.</li>
<li>Here, We do not try to teach <strong>which attribute</strong> represents <strong>what</strong>?</li>
<li>We try to teach that <strong>no two</strong> attributes should represent <strong>same concept</strong>.</li>
</ul>
<p><img alt="png" src="../../assets/projects/clothes_retrieval/output_20_0.png" /></p>
<p><strong>Mathematical Formulation</strong></p>
<ul>
<li>We often calculate similarity of two vectors using <strong>cosine similarity</strong> measure.</li>
<li>Cosine similarity has an interpretation as the cosine of the <strong>angle</strong> between the two vectors</li>
<li>Cosine similarity is <strong>not invariant to shifts</strong>. If x was shifted to x+1, the cosine similarity would change.</li>
</ul>
<p><img alt="png" src="../../assets/projects/clothes_retrieval/output_23_0.png" /></p>
<ul>
<li>Unlike the cosine, the <strong>correlation</strong> is <strong>invariant</strong> to both scale and location changes of x and y.</li>
</ul>
<p><img alt="png" src="../../assets/projects/clothes_retrieval/output_25_0.png" /></p>
<ul>
<li><strong>Correlation</strong> is the cosine similarity between centered versions of x and y</li>
</ul>
<p><img alt="png" src="../../assets/projects/clothes_retrieval/output_27_0.png" /></p>
<ul>
<li>In a <strong>batch</strong> of images, <strong>attribute vector</strong> represents values of <strong>particular dimension</strong> across all images</li>
<li>For e.g if batch size = 512 and embedding dim = 2048, then we have 2048 attribute vectors each of length 512</li>
<li>Now consider another batch of <strong>slightly different</strong> version of the same <strong>images</strong> in first batch.</li>
</ul>
<p><strong>Our goal is to</strong></p>
<ol>
<li><strong>Maximize</strong> cosine similarity of <strong>same attributes</strong> in both batches</li>
<li>
<p><strong>Minimize</strong> cosine similarity of <strong>different attributes</strong> in both batches</p>
</li>
<li>
<p>Here, I used correlation as a <strong>proxy loss</strong> as both have same output range [-1,1]</p>
</li>
</ol>
<p><strong>I divided loss function in two parts</strong></p>
<ol>
<li><strong>Correlation</strong> of attribute vectors at <strong>same index</strong> should be <strong>1</strong>. To make model generalize better I decreased the predicted correlation by <strong>margin</strong> m. For e.g if correlation is 0.9 we make it 0.6 so model tries to make it higher.</li>
<li>Correlation of attribute vectors at <strong>different index</strong> should be <strong>0</strong>.</li>
<li>Since there are <strong>N^2-N</strong> pairs of <strong>different attribute</strong> vectors I assigned <strong>lower weight</strong> compared to positive attribute pair. </li>
</ol>
<p><strong>Code for attribute loss</strong></p>
<pre><code class="language-python">def attribute_loss(emb_1, emb_2, alpha=5e-4, margin=0.3):

    # per feature-dimension normalisation
    standardize = lambda x : (x - tf.reduce_mean(x, axis=0)) / tf.math.reduce_std(x, axis=0)
    emb_1_std = standardize(emb_1) # BxE
    emb_2_std = standardize(emb_2) # BxE

    # similarity of pairwise feature-dimension
    bsize = tf.cast(tf.shape(emb_1)[0], tf.float32)
    cos_t = tf.matmul(emb_1_std, emb_2_std, transpose_a=True) / bsize # Embed x Embed
    acos_t = tf.acos(tf.clip_by_value(cos_t, -1.0, 1.0))

    # diagonal values rep. expected similarity of same feature-dim
    same_dim_mask = tf.eye(emb_1.shape[1]) # Embed x Embed

    # non-diagonal values rep. expected similarity of different features-dim
    diff_dim_mask = 1.0 - same_dim_mask # Embed x Embed

    # increase angle betweem same feature-dims : Cos(angle + m)(i==j)
    cosine_same     = tf.cos(acos_t + margin)
    same_dim_loss   = tf.square(same_dim_mask - cosine_same) * same_dim_mask

    # decrease angle between different feature-dims : Cos(angle - m)(i!=j)
    # cosine_diff     = tf.cos(acos_t - margin)
    diff_dim_loss   = tf.square(same_dim_mask - cos_t) * diff_dim_mask

    # final weighted loss
    weighted_loss = tf.reduce_sum(same_dim_loss + diff_dim_loss * alpha)
    return weighted_loss
</code></pre>
<h3 id="step-2-reducing-the-domain-gap-using-pinch-of-supervision"><strong>Step 2</strong> : Reducing the domain gap using pinch of supervision<a class="headerlink" href="#step-2-reducing-the-domain-gap-using-pinch-of-supervision" title="Permanent link">&para;</a></h3>
<ul>
<li>Model trained with <strong>attribute loss</strong> can learn <strong>diverse set of attributes</strong> for each image.</li>
<li>Although consumer and shop images have <strong>inherent biases</strong> due to different source of <strong>data generation</strong></li>
<li>This is very well known as <strong>domain gap</strong> where two similar objects can perceived differently by model due to pixel level differences</li>
<li>I used <strong>combination</strong> of <strong>attribute loss</strong> and <strong>instance loss</strong> to reduce this domain gap with only <strong>3 more epochs</strong> for <strong>finetuning</strong></li>
</ul>
<p><strong>1. Attribute loss</strong>:</p>
<ul>
<li>In stage one, attribute loss was calculated between <strong>two different versions of same image</strong> as we did not have any other information</li>
<li>Here we calculate it between attributes of <strong>same cloth type</strong> but one image from <strong>consumer</strong> and other from <strong>shop</strong> using label information</li>
</ul>
<p><strong>2. Instance loss</strong>:</p>
<ul>
<li>Attribute loss encourages model to learn <strong>features</strong> which are <strong>consistent</strong> in consumer and shop domain</li>
<li>Instance loss is normal classification loss which uses these attributes to <strong>group similar</strong> cloths in tight clusters and <strong>increase distance</strong> between other groups.</li>
<li>I used <strong>arcface</strong> as an instance loss.</li>
</ul>
<p><strong>3. Using weights from attribute model to</strong></p>
<ol>
<li>Initialize <strong>backbone</strong></li>
<li>Initialize weights of newly added <strong>classification layer</strong>.</li>
<li>Arcface tries to reduce cosine similarity of <strong>weights</strong> vector and <strong>instance</strong> vector.</li>
<li>I used <strong>average</strong> of all <strong>embeddings</strong> produced by unsupervised model for <strong>each class</strong> as the <strong>initial weight</strong> vector of that class.</li>
</ol>
<p><img alt="png" src="../../assets/projects/clothes_retrieval/output_33_0.png" /></p>
<p><strong>Code for classifier weights calculation</strong></p>
<pre><code class="language-python"># Get classifier weights
def classifier_weights(dataset, model, num_class):
    # calculate avg embedding for each class as w_init for fc
    out_layer   = params.model.class_layer
    weights     = np.zeros(shape=(num_class, model.outputs[out_layer].shape[-1]),
                           dtype=np.float32) # (n_class, emb_dim)
    # (n_class,) extra 1 for ignoring zero div
    class_cnt   = np.ones(shape=(num_class,), dtype=np.float32) 
    for data in tqdm(dataset):
        user, shop, class_id = data
        all_images  = tf.concat([user, shop], axis=0)
        class_ids   = tf.concat([class_id, class_id], axis=0)
        embeds      = model(all_images, training=False)[out_layer].numpy()
        weights[class_ids] += embeds
        class_cnt[class_ids] += 1
    weights = np.divide(weights, class_cnt[:, np.newaxis])
    return weights
</code></pre>
<h2 id="experiments"><strong>Experiments</strong><a class="headerlink" href="#experiments" title="Permanent link">&para;</a></h2>
<h3 id="model-details">Model details<a class="headerlink" href="#model-details" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Model</strong> Resnet50</li>
<li><strong>Batch Size</strong> 512</li>
<li><strong>Input resolution</strong> 96</li>
<li><strong>Embedding dimension</strong> 2048</li>
</ul>
<p>For training details refer code notebook</p>
<h3 id="results">Results<a class="headerlink" href="#results" title="Permanent link">&para;</a></h3>
<p><img alt="png" src="../../assets/projects/clothes_retrieval/output_39_0.png" /></p>
<h2 id="final-comments"><strong>Final Comments</strong><a class="headerlink" href="#final-comments" title="Permanent link">&para;</a></h2>
<ul>
<li>Although <strong>unsupervised loss</strong> has <strong>lower accuracy</strong> when source <strong>domains are different</strong>, it performs significantly <strong>better</strong> in <strong>mix domain</strong> (Exp 1 Last Block).</li>
<li>Which suggests that <strong>attribute loss</strong> can work very well in <strong>task agnostic</strong> manner.</li>
<li>Both <strong>attribute loss</strong> and fc7 <strong>weights initialization</strong> using avg class embedding <strong>improves results</strong></li>
<li><strong>Supervised training</strong> from <strong>scratch</strong> performed significantly <strong>worse</strong> when training from scratch for <strong>3 epoch</strong></li>
</ul>
<h2 id="demo-on-validation-dataset"><strong>Demo on validation dataset</strong><a class="headerlink" href="#demo-on-validation-dataset" title="Permanent link">&para;</a></h2>
<ul>
<li>No image was used during training</li>
<li>Results are in <strong>descending</strong> order of <strong>recall</strong></li>
<li><strong>First</strong> column is consumer <strong>query</strong> image</li>
<li><strong>Other</strong> columns are <strong>retrieved</strong> shop images</li>
<li><strong>Green</strong> box is <strong>True Positive</strong>, <strong>Red</strong> box is <strong>False positive</strong></li>
</ul>
<h3 id="model-unsupervised-learning-attribute-loss-exp-1"><strong>Model</strong> :  Unsupervised Learning + Attribute Loss (Exp 1)<a class="headerlink" href="#model-unsupervised-learning-attribute-loss-exp-1" title="Permanent link">&para;</a></h3>
<p><img alt="jpeg" src="../../assets/projects/clothes_retrieval/output_45_0.jpg" /></p>
<h3 id="model-attribute-loss-instance-loss-fc7-weights-init-exp-2"><strong>Model</strong> :  Attribute Loss + Instance Loss + fc7 weights init (Exp-2)<a class="headerlink" href="#model-attribute-loss-instance-loss-fc7-weights-init-exp-2" title="Permanent link">&para;</a></h3>
<p><img alt="jpeg" src="../../assets/projects/clothes_retrieval/output_47_0.jpg" /></p>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
    <nav class="md-footer__inner md-grid" aria-label="Footer" >
      
        
        <a href="../../experience/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Experience" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Experience
            </div>
          </div>
        </a>
      
      
        
        <a href="../deep_face_recognition/" class="md-footer__link md-footer__link--next" aria-label="Next: Deep Face Recognition" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Deep Face Recognition
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.16e2a7d4.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.8492ddcf.min.js"></script>
      
    
  </body>
</html>